{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYe-Q24_rwTU"
   },
   "source": [
    "## YOLO V5 데이터 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_MJ0zGAz6UH"
   },
   "source": [
    "### yaml 파일\n",
    "\n",
    "- 학습 데이터의 경로, 클래스 갯수 및 종류가 적혀있는 파일\n",
    "- train : 학습 데이터 폴더 경로\n",
    "- val : 검증 데이터 폴더 경로\n",
    "- nc : 학습할 클래스 개수\n",
    "- names : 학습할 클래스 이름\n",
    "\n",
    "### label 파일(.txt)\n",
    "\n",
    "- https://github.com/AlexeyAB/Yolo_mark\n",
    "- https://github.com/tzutalin/labelImg\n",
    "- 위의 깃허브 링크를 통해 YOLO 데이터 레이블 제작\n",
    "\n",
    "### 데이터 폴더 구조\n",
    "\n",
    "- 전체 데이터 폴더\n",
    "  - 이미지 데이터 폴더\n",
    "    - train 이미지 데이터 폴더\n",
    "    - val 이미지 데이터 폴더\n",
    "  - 텍스트 레이블 폴더\n",
    "    - train 텍스트 레이블 폴더\n",
    "    - val 텍스트 레이블 폴더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qnj0mZgjsXNh"
   },
   "source": [
    "## YOLOv5 기본설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUbxavOVrTKO",
    "outputId": "98ad14c1-486a-4ac6-f0ea-71a602974042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 19, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 5540 (delta 5), reused 4 (delta 2), pack-reused 5521\u001b[K\n",
      "Receiving objects: 100% (5540/5540), 8.17 MiB | 32.92 MiB/s, done.\n",
      "Resolving deltas: 100% (3781/3781), done.\n",
      "/content/yolov5\n",
      "\u001b[K     |████████████████████████████████| 645kB 7.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Github에서 YOLOv5 다운로드\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "# Dependencies 설치\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install dependencies, 해당 코드를 실행하지 않으면 train.py 파일이 실행되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5iDorBVusRwc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 이미지를 보여주기 위한 라이브러리\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yCPiyj7rxoc",
    "outputId": "85acbd16-aa5f-4daf-c0ad-d807defa48d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.8.0+cu101 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qtu4YvXMzELf"
   },
   "source": [
    "## 데이터셋 다운로드(coco128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmH1ygZq82Fh"
   },
   "source": [
    "- coco128 : COCO train 2017 데이터셋의 처음 128개 이미지 포함\n",
    "  - 학습 및 테스트에 동일한 128개의 이미지 사용\n",
    "  - 과적합 현상 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "68e7b29e91c04dac8c7ee3c0b631130f",
      "d80f54f3e3b6462bb3d8651d3a414f51",
      "17957ea266ab4d2f986a70520622d7b5",
      "be501700d2f14b2f8091a93f19814704",
      "b7b338b5a15d47e583639ab96fbd4d09",
      "5dd87f1a80bb4000a1b16eeec5de4486",
      "c17513cfb3c54cf9adc6809727834328",
      "696cda095430410bbca837dc70893da2"
     ]
    },
    "id": "9VudclRNsgDc",
    "outputId": "1db92457-d845-4170-b19c-5f7c62f299c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e7b29e91c04dac8c7ee3c0b631130f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22091032.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
    "\n",
    "# 다운로드 받은 파일을 압축해제하고 압축파일은 삭제\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaJL236l0R_d"
   },
   "source": [
    "## YOLOv5 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mq4NEUSG0Y6k"
   },
   "source": [
    "### VOLO V5 인자\n",
    "\n",
    "- img : 이미지 크기\n",
    "- epochs : 학습 횟수\n",
    "- data : yaml 파일 경로\n",
    "- weights : Pre-Trained 모델 파일 경로\n",
    "- batch-size : 배치 크기\n",
    "- cfg : 아키텍쳐 yaml 파일 경로\n",
    "  - yolo v5는 s, m, l, x 4가지 버전 존재\n",
    "  - s < m < l < x (모델 무게)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mS6fN9jC0Kc-",
    "outputId": "78874dc7-e955-4b46-f22f-4716ca974a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v4.0-162-g9b92d3e torch 1.8.0+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], linear_lr=False, local_rank=-1, multi_scale=False, name='yolov5s_clothing_detect', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov5s_clothing_detect', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov5s.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2021-03-28 13:03:28.874390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v4.0/yolov5s.pt to yolov5s.pt...\n",
      "100% 14.1M/14.1M [00:00<00:00, 64.1MB/s]\n",
      "\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7276605 parameters, 7276605 gradients, 17.1 GFLOPS\n",
      "\n",
      "Transferred 362/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 2372.70it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../coco128/labels/train2017.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 198.96it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 962134.25it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 154.01it/s]\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
      "Image sizes 640 train, 640 test\n",
      "Using 2 dataloader workers\n",
      "Logging results to runs/train/yolov5s_clothing_detect\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       0/2     3.24G   0.04237   0.06416    0.0212    0.1277       183       640: 100% 8/8 [00:05<00:00,  1.42it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 : 640\n",
    "# 배치 크기 : 16\n",
    "# 학습 횟수 : 3\n",
    "# 아키텍쳐 yaml : coco128.yaml\n",
    "# 모델 버전 : yolov5s\n",
    "# nosave 옵션 : 마지막 checkpoint만 저장(모델 가중치를 중간 저장하지 않음)\n",
    "# cache 옵션 : 빠른 학습속도를 위한 이미지 캐싱\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --name yolov5s_clothing_detect --nosave --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl44OTOP5cky"
   },
   "source": [
    "## YOLOv5 학습 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUdS8Req2D4R"
   },
   "outputs": [],
   "source": [
    "# 각 배치에는 16개의 이미지가 포함되어 있음\n",
    "# train_batch 이미지 파일에는 객체에 대한 바운딩 박스만 그려져 있음\n",
    "Image(filename='runs/train/yolov5s_clothing_detect/train_batch0.jpg', width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiYsCo7S5kx3"
   },
   "outputs": [],
   "source": [
    "# test_batch_labels 이미지 파일에는 객체에 대한 바운딩 박스에 객체명이 레이블링됨\n",
    "Image(filename='runs/train/yolov5s_clothing_detect/test_batch0_labels.jpg', width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JcS4Cbn6Hpb"
   },
   "outputs": [],
   "source": [
    "# test_batch_pred 이미지 파일에는 객체에 대한 바운딩 박스에 객체명 및 점수가 포함되어 있음\n",
    "# 점수는 conf 옵션이 따로 설정되어 있지 않았을 경우, 기본값(0.001)로 설정되어 해당 값보다 작은 점수로 탐지된 객체는 표시되지 않음\n",
    "Image(filename='runs/train/yolov5s_clothing_detect/test_batch0_pred.jpg', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8qkuIWK7Keb"
   },
   "source": [
    "## 이미지 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7AKmn1N7PpL"
   },
   "outputs": [],
   "source": [
    "# 학습된 모델(해당 예제에서는 yolo5s.pt)을 가지고 임의의 이미지에 대해서 객체 탐지 수행\n",
    "# source 옵션은 객체 탐지를 수행할 이미지들이 저장되어 있는 경로\n",
    "# 아래 코드는 이미지 저장 경로가 data/images로 설정되어 있음\n",
    "# 객체 탐지 수행 결과는 기본값으로 runs/detect/exp/\n",
    "# conf 옵션을 0.25로 설정하여 해당 점수보다 낮은 점수를 가진 객체는 바운딩 박스가 표시되지 않음\n",
    "!python detect.py --weights runs/train/yolov5s_clothing_detect/weights/last.pt --img 640 --conf 0.25 --source data/images/\n",
    "Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgmgDG4b7shS"
   },
   "source": [
    "위의 이미지 테스트는 128개의 이미지를 가지고 학습된 모델이기 때문에 정확한 객체 탐지가 수행되지 않음.\n",
    "\n",
    "아래의 코드에서 YOLOv5 버전 중 가장 무거운 모델인 yolov5x을 사용하여 객체 탐지 성능 비교.\n",
    "\n",
    "다운로드 받은 모델은 사전학습이 되어있는 상태."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htlDAifM_Je2"
   },
   "outputs": [],
   "source": [
    "# project 옵션과 name 옵션을 합한 디렉토리 생성\n",
    "# project 기본값은 runs/detect\n",
    "# name 기본값 : exp\n",
    "# 아래 코드에서는 project = default(runs/detect)이고, name = exp2이므로 detect.py를 실행한 결과가 저장되는 경로는 runs/detect/exp2\n",
    "!python detect.py --weights yolov5x.pt --img 640 --conf 0.25 --source data/images/ --name exp2\n",
    "Image(filename='runs/detect/exp2/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHrR1et1_iKy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eYe-Q24_rwTU",
    "Qnj0mZgjsXNh",
    "Qtu4YvXMzELf"
   ],
   "name": "YOLOv5 Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17957ea266ab4d2f986a70520622d7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dd87f1a80bb4000a1b16eeec5de4486",
      "max": 22091032,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7b338b5a15d47e583639ab96fbd4d09",
      "value": 22091032
     }
    },
    "5dd87f1a80bb4000a1b16eeec5de4486": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e7b29e91c04dac8c7ee3c0b631130f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17957ea266ab4d2f986a70520622d7b5",
       "IPY_MODEL_be501700d2f14b2f8091a93f19814704"
      ],
      "layout": "IPY_MODEL_d80f54f3e3b6462bb3d8651d3a414f51"
     }
    },
    "696cda095430410bbca837dc70893da2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7b338b5a15d47e583639ab96fbd4d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "be501700d2f14b2f8091a93f19814704": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_696cda095430410bbca837dc70893da2",
      "placeholder": "​",
      "style": "IPY_MODEL_c17513cfb3c54cf9adc6809727834328",
      "value": " 21.1M/21.1M [00:01&lt;00:00, 17.2MB/s]"
     }
    },
    "c17513cfb3c54cf9adc6809727834328": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d80f54f3e3b6462bb3d8651d3a414f51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
